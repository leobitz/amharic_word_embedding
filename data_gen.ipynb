{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "    \n",
    "    def __init__(self, percent=100):\n",
    "        self.n_consonant = 0\n",
    "        self.n_vowel = 10\n",
    "        self.corpus = open('data/news.txt', encoding='utf8').read()\n",
    "        self.words = self.corpus.split(' ')\n",
    "        width = int(len(self.words) * percent/100)\n",
    "        self.words = self.words[:width]\n",
    "        self.char2int, self.int2char, self.char2tup, self.tup2char = self.load_charset()\n",
    "        self.vocab, self.word2int, self.int2word = self.get_vocab(self.words)\n",
    "        self.max_word_len = 11\n",
    "        del self.corpus\n",
    "    \n",
    "    def get_vocab(self, words):\n",
    "        word2int = {}\n",
    "        int2word = {}\n",
    "        vocab = list(sorted(set(words)))\n",
    "        for word in vocab:\n",
    "            int2word[len(word2int)] = word\n",
    "            word2int[word] = len(word2int)\n",
    "        return vocab, word2int, int2word\n",
    "    \n",
    "    def load_charset(self):\n",
    "        charset = open('data/charset.txt', encoding='utf-8').readlines()\n",
    "        self.n_consonant = len(charset)\n",
    "        char2int, int2char, char2tup, tup2char = {}, {}, {}, {}\n",
    "        j = 0\n",
    "        for k in range(len(charset)):\n",
    "            row = charset[k][:-1].split(',')\n",
    "            for i in range(len(row)):\n",
    "                char2tup[row[i]] = (k, i)\n",
    "                int2char[j] = row[i]\n",
    "                char2int[row[i]] = j\n",
    "                tup = \"{0}-{1}\".format(k, i)\n",
    "                tup2char[tup] = row[i]\n",
    "                j += 1\n",
    "        return char2int, int2char, char2tup, tup2char\n",
    "        \n",
    "    \n",
    "    def word2vec(self, word):\n",
    "        cons = np.zeros((self.max_word_len, self.n_consonant), dtype=np.float32)\n",
    "        vowel = np.zeros((self.max_word_len, self.n_vowel), dtype=np.float32)\n",
    "        for i in range(len(word)):\n",
    "            char = word[i]\n",
    "            t = self.char2tup[char]\n",
    "            cons[i][t[0]] = 1\n",
    "            vowel[i][t[1]] = 1\n",
    "        con, vow = self.char2tup[' ']\n",
    "        cons[i+1:, con] = 1\n",
    "        vowel[i+1:, vow] = 1\n",
    "        vec = np.concatenate([cons, vowel], axis=1)\n",
    "        return vec\n",
    "\n",
    "    def word2vec2(self, word):\n",
    "        max_n_char = len(self.char2int)\n",
    "        vec = np.zeros((self.max_word_len, max_n_char), dtype=np.float32)\n",
    "        for i in range(len(word)):\n",
    "            char = word[i]\n",
    "            t = self.char2int[char]\n",
    "            vec[i][t] = 1\n",
    "        spacei = self.char2int[' ']\n",
    "        vec[i+1:, spacei] = 1\n",
    "        return vec\n",
    "    \n",
    "    def one_hot(self, n, size):\n",
    "        v = np.zeros((size,))\n",
    "        v[n] = 1\n",
    "        return v\n",
    "    \n",
    "    def one_hot_decode(self, vec):\n",
    "        indexes = np.argmax(vec, axis=1)\n",
    "        words = []\n",
    "        for i in indexes:\n",
    "            words.append(self.int2word[i])\n",
    "        return words\n",
    "            \n",
    "        \n",
    "    \n",
    "    def sentense_to_vec(self, words):\n",
    "        vecs = []\n",
    "        for w in words:\n",
    "            vecs.append(self.word2vec(w))\n",
    "        vec = np.concatenate(vecs)\n",
    "        return vec\n",
    "    \n",
    "\n",
    "    def gen(self, batch_size=100, n_batches=-1, windows_size=4):\n",
    "        batch = 0\n",
    "        n_words = len(self.words)\n",
    "        if n_batches > 0:\n",
    "            n_words = batch_size * n_batches\n",
    "        c_word = windows_size // 2\n",
    "        while True:\n",
    "            x = []\n",
    "            y = []\n",
    "            for i in range(batch_size):\n",
    "                j = c_word - windows_size // 2\n",
    "                k = c_word + windows_size // 2 + 1\n",
    "                context = self.words[j:k]\n",
    "                target = context.pop(windows_size//2)\n",
    "                vec = self.sentense_to_vec(context)\n",
    "                x.append(vec)\n",
    "                y.append(self.one_hot(self.word2int[target], len(self.vocab)))\n",
    "                c_word += 1\n",
    "            batch += 1\n",
    "            if c_word > n_words - windows_size // 2:\n",
    "                print(\"word \", c_word)\n",
    "                c_word = windows_size // 2\n",
    "            rand = np.random.choice(batch_size, size=batch_size, replace=False)\n",
    "            x = np.stack(x)\n",
    "            x = x.reshape((x.shape[0], x.shape[1], x.shape[2],1))\n",
    "            y = np.stack(y)\n",
    "#             y = y[rand]\n",
    "#             x = x[rand]\n",
    "            yield x, y\n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg = DataGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dg.word2vec(\"ልዮው&\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.words = open('data/news.txt', encoding='utf8').read().split(' ')\n",
    "        self.vocab, self.word2int, self.int2word, self.word_indexes = self.word2index()\n",
    "        \n",
    "    def word2index(self):\n",
    "        vocab = list(set(self.words))\n",
    "        word2int, int2word = {}, {}\n",
    "        for i, word in enumerate(vocab):\n",
    "            word2int[word] = i\n",
    "            int2word[i] = word\n",
    "        word_indexes = []\n",
    "        for word in self.words:\n",
    "            word_indexes.append(word2int[word])\n",
    "            \n",
    "        return vocab, word2int, int2word, word_indexes\n",
    "            \n",
    "    \n",
    "    def get_words_indexes(self, start, length):\n",
    "        return self.word_indexes[start:start+length]\n",
    "    \n",
    "    def gen(self, batch_size=100, window_size=4, n_batches=-1):\n",
    "        assert batch_size % window_size == 0\n",
    "        batch = 0\n",
    "        half_window = window_size // 2\n",
    "        max_batch = (len(self.words) - half_window) // batch_size\n",
    "        if n_batches > 0 and n_batches < max_batch:\n",
    "            max_batch = n_batches\n",
    "        current_target = half_window\n",
    "        while True:\n",
    "            if batch == max_batch:\n",
    "                batch = 0\n",
    "            x = []\n",
    "            y = []\n",
    "            for i in range(batch_size // window_size):\n",
    "                start = current_target - half_window\n",
    "                context = self.get_words_indexes(start, window_size + 1)\n",
    "                target = context.pop(half_window)\n",
    "                np.random.shuffle(context)\n",
    "                for c in context:\n",
    "                    x.append(c)\n",
    "                    y.append(target)\n",
    "                current_target += 1\n",
    "            yield x, y\n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg2 = DataGen2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = dg2.gen(batch_size=16, window_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([131880,\n",
       "  116992,\n",
       "  9579,\n",
       "  199727,\n",
       "  170696,\n",
       "  38580,\n",
       "  131880,\n",
       "  9579,\n",
       "  116992,\n",
       "  38580,\n",
       "  170696,\n",
       "  151706,\n",
       "  116992,\n",
       "  239865,\n",
       "  151706,\n",
       "  9579],\n",
       " [38580,\n",
       "  38580,\n",
       "  38580,\n",
       "  38580,\n",
       "  116992,\n",
       "  116992,\n",
       "  116992,\n",
       "  116992,\n",
       "  9579,\n",
       "  9579,\n",
       "  9579,\n",
       "  9579,\n",
       "  170696,\n",
       "  170696,\n",
       "  170696,\n",
       "  170696])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
