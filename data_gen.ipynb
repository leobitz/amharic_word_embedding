{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen:\n",
    "    \n",
    "    def __init__(self, percent=100):\n",
    "        self.n_consonant = 0\n",
    "        self.n_vowel = 10\n",
    "        self.corpus = open('data/news.txt', encoding='utf8').read()\n",
    "        self.words = self.corpus.split(' ')\n",
    "        width = int(len(self.words) * percent/100)\n",
    "        self.words = self.words[:width]\n",
    "        self.char2int, self.int2char, self.char2tup, self.tup2char = self.load_charset()\n",
    "        self.vocab, self.word2int, self.int2word = self.get_vocab(self.words)\n",
    "        self.max_word_len = 11\n",
    "        del self.corpus\n",
    "    \n",
    "    def get_vocab(self, words):\n",
    "        word2int = {}\n",
    "        int2word = {}\n",
    "        vocab = list(sorted(set(words)))\n",
    "        for word in vocab:\n",
    "            int2word[len(word2int)] = word\n",
    "            word2int[word] = len(word2int)\n",
    "        return vocab, word2int, int2word\n",
    "    \n",
    "    def load_charset(self):\n",
    "        charset = open('data/charset.txt', encoding='utf-8').readlines()\n",
    "        self.n_consonant = len(charset)\n",
    "        char2int, int2char, char2tup, tup2char = {}, {}, {}, {}\n",
    "        j = 0\n",
    "        for k in range(len(charset)):\n",
    "            row = charset[k][:-1].split(',')\n",
    "            for i in range(len(row)):\n",
    "                char2tup[row[i]] = (k, i)\n",
    "                int2char[j] = row[i]\n",
    "                char2int[row[i]] = j\n",
    "                tup = \"{0}-{1}\".format(k, i)\n",
    "                tup2char[tup] = row[i]\n",
    "                j += 1\n",
    "        return char2int, int2char, char2tup, tup2char\n",
    "        \n",
    "    \n",
    "    def word2vec(self, word):\n",
    "        cons = np.zeros((self.max_word_len, self.n_consonant), dtype=np.float32)\n",
    "        vowel = np.zeros((self.max_word_len, self.n_vowel), dtype=np.float32)\n",
    "        for i in range(len(word)):\n",
    "            char = word[i]\n",
    "            t = self.char2tup[char]\n",
    "            cons[i][t[0]] = 1\n",
    "            vowel[i][t[1]] = 1\n",
    "        con, vow = self.char2tup[' ']\n",
    "        cons[i+1:, con] = 1\n",
    "        vowel[i+1:, vow] = 1\n",
    "        vec = np.concatenate([cons, vowel], axis=1)\n",
    "        return vec\n",
    "\n",
    "    def word2vec2(self, word):\n",
    "        max_n_char = len(self.char2int)\n",
    "        vec = np.zeros((self.max_word_len, max_n_char), dtype=np.float32)\n",
    "        for i in range(len(word)):\n",
    "            char = word[i]\n",
    "            t = self.char2int[char]\n",
    "            vec[i][t] = 1\n",
    "        spacei = self.char2int[' ']\n",
    "        vec[i+1:, spacei] = 1\n",
    "        return vec\n",
    "    \n",
    "    def one_hot(self, n, size):\n",
    "        v = np.zeros((size,))\n",
    "        v[n] = 1\n",
    "        return v\n",
    "    \n",
    "    def one_hot_decode(self, vec):\n",
    "        indexes = np.argmax(vec, axis=1)\n",
    "        words = []\n",
    "        for i in indexes:\n",
    "            words.append(self.int2word[i])\n",
    "        return words\n",
    "            \n",
    "        \n",
    "    \n",
    "    def sentense_to_vec(self, words):\n",
    "        vecs = []\n",
    "        for w in words:\n",
    "            vecs.append(self.word2vec(w))\n",
    "        vec = np.concatenate(vecs)\n",
    "        return vec\n",
    "    \n",
    "\n",
    "    def gen(self, batch_size=100, n_batches=-1, windows_size=4):\n",
    "        batch = 0\n",
    "        n_words = len(self.words)\n",
    "        if n_batches > 0:\n",
    "            n_words = batch_size * n_batches\n",
    "        c_word = windows_size // 2\n",
    "        while True:\n",
    "            x = []\n",
    "            y = []\n",
    "            for i in range(batch_size):\n",
    "                j = c_word - windows_size // 2\n",
    "                k = c_word + windows_size // 2 + 1\n",
    "                context = self.words[j:k]\n",
    "                target = context.pop(windows_size//2)\n",
    "                vec = self.sentense_to_vec(context)\n",
    "                x.append(vec)\n",
    "                y.append(self.one_hot(self.word2int[target], len(self.vocab)))\n",
    "                c_word += 1\n",
    "            batch += 1\n",
    "            if c_word > n_words - windows_size // 2:\n",
    "                print(\"word \", c_word)\n",
    "                c_word = windows_size // 2\n",
    "            rand = np.random.choice(batch_size, size=batch_size, replace=False)\n",
    "            x = np.stack(x)\n",
    "            x = x.reshape((x.shape[0], x.shape[1], x.shape[2],1))\n",
    "            y = np.stack(y)\n",
    "#             y = y[rand]\n",
    "#             x = x[rand]\n",
    "            yield x, y\n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg = DataGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
