{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-693f739c1093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# import keras.backend as K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_handle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/sda6/Library/Projects/amharic_word_embedding/data_handle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/sda6/Library/Projects/amharic_word_embedding/gensim_wrapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import LSTM, TimeDistributed\n",
    "# from keras.layers import Concatenate, Flatten\n",
    "# from keras.layers import GRU, Conv2D, MaxPooling2D\n",
    "# from keras.layers import Input, Reshape, Dot, Add\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# import keras\n",
    "# import keras.backend as K\n",
    "from data_handle import *\n",
    "from gensim_wrapper import *\n",
    "from utils import *\n",
    "import gensim\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "seed_val = 1000\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "tf.set_random_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseVec(file, delimiter, word2int):\n",
    "    lines = open(file, encoding='utf8').readlines()\n",
    "    vocab_size, embed_size = [int(s) for s in lines[0].split()]\n",
    "    vocab_size  = min(len(word2int), vocab_size)\n",
    "    embeddings = np.zeros((vocab_size + 1, embed_size), dtype=np.float64)\n",
    "    for i in range(1, vocab_size):\n",
    "        try:\n",
    "            line = lines[i][:-1].split(delimiter)\n",
    "            word = line[0]\n",
    "            if '*###*' in word or 'unk' in word:\n",
    "                continue\n",
    "            if word in word2int:\n",
    "                wordvec = np.array([np.float64(j) for j in line[1:] if j != ''])\n",
    "                embeddings[word2int[word]] = wordvec\n",
    "        except Exception as e:\n",
    "#             print(lines[i])\n",
    "            print(e)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read_file(filename='data/news_mini.txt')\n",
    "words, word2freq = min_count_threshold(words)\n",
    "vocab, word2int, int2word = build_vocab(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwords = read_file(filename='data/news.txt')\n",
    "xwords, xword2freq = min_count_threshold(xwords)\n",
    "xvocab, xword2int, xint2word = build_vocab(xwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word2int['*###*']\n",
    "del xword2int['*###*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58385, 75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Library\\Projects\\amharic_word_embedding\\data_handle.py:338: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return array / norms\n"
     ]
    }
   ],
   "source": [
    "w2v_mini = parseVec('results/w2v_mini.txt', ' ', word2int)\n",
    "w2v = parseVec('results/w2v.txt', ' ', word2int=xword2int)\n",
    "print(w2v.shape)\n",
    "mini_utils= Utils(embedding=normalize(w2v_mini), int2word=int2word, word2int=word2int)\n",
    "ref_utils= Utils(embedding=normalize(w2v), int2word=xint2word, word2int=xword2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compare = 20\n",
    "score = np.zeros((n_compare, n_compare))\n",
    "for i in range(n_compare):\n",
    "    for j in range(n_compare):\n",
    "        x = i + 1\n",
    "        y = j + 1\n",
    "        s = 1/(x * x + y * y)**.5\n",
    "        score[i][j] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Library\\Projects\\amharic_word_embedding\\data_handle.py:338: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return array / norms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mine: 428.0189662328501 W2v: 602.7277825558499\n",
      "Mine: 469.7207599184511 W2v: 602.7277825558499\n",
      "Mine: 485.9659751874172 W2v: 602.7277825558499\n",
      "Mine: 496.06189022810554 W2v: 602.7277825558499\n"
     ]
    }
   ],
   "source": [
    "indexes = np.random.randint(1, 1000, 1000)\n",
    "for exp in range(1, 2):\n",
    "    for part in range(0, 5):\n",
    "        file = 'results/mini/mw2v_{0}_0.txt'.format(part, exp)\n",
    "        mine = parseVec(file, ' ', word2int)\n",
    "        mine_utils= Utils(embedding=normalize(mine), int2word=int2word, word2int=word2int)\n",
    "        mscore = 0\n",
    "        wscore = 0\n",
    "        for inx in indexes:\n",
    "            word = words[inx]\n",
    "            r1 = mine_utils.sorted_sim(word, n_compare)\n",
    "            r2 = mini_utils.sorted_sim(word, n_compare)\n",
    "            r3 = ref_utils.sorted_sim(word, 500)\n",
    "            ref_result = []\n",
    "            for i in range(len(r3)):\n",
    "                if r3[i][0] in word2int:\n",
    "                    ref_result.append(r3[i][0])\n",
    "                if len(ref_result) == n_compare:\n",
    "                    break\n",
    "\n",
    "            for i in range(1, len(r1)): \n",
    "                try:\n",
    "                    x = ref_result.index(r1[i][0])\n",
    "                    mscore += score[i][x]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    y = ref_result.index(r2[i][0])\n",
    "                    wscore += score[i][y]\n",
    "                except:\n",
    "                    pass\n",
    "        #         print(\"{0}\\t\\t\\t{1}\\t\\t\\t{2}\".format(r1[i][0], r2[i][0], ref_result[i]))\n",
    "        print(\"Mine: {0} W2v: {1}\".format(mscore, wscore))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
