{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def anomaly(model):\n",
    "    lines = open('data/anomaly.txt', encoding='utf-8').readlines()\n",
    "    correct = 0\n",
    "    for line in lines:\n",
    "        vals = line[:-1].split(' ')\n",
    "        index = int(vals[-1])\n",
    "        pred = model.doesnt_match(vals[:4])\n",
    "        if pred == vals[index]:\n",
    "            correct += 1\n",
    "        # print(pred, vals[index])\n",
    "    return correct * 100 / len(lines)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-14 13:03:08,879 : INFO : collecting all words and their counts\n",
      "2018-10-14 13:03:08,879 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-14 13:03:08,938 : INFO : PROGRESS: at sentence #10000, processed 150787 words, keeping 38040 word types\n",
      "2018-10-14 13:03:08,996 : INFO : PROGRESS: at sentence #20000, processed 309265 words, keeping 61588 word types\n",
      "2018-10-14 13:03:09,051 : INFO : PROGRESS: at sentence #30000, processed 477795 words, keeping 81867 word types\n",
      "2018-10-14 13:03:09,135 : INFO : PROGRESS: at sentence #40000, processed 647737 words, keeping 100652 word types\n",
      "2018-10-14 13:03:09,182 : INFO : PROGRESS: at sentence #50000, processed 805941 words, keeping 116075 word types\n",
      "2018-10-14 13:03:09,250 : INFO : PROGRESS: at sentence #60000, processed 967897 words, keeping 129675 word types\n",
      "2018-10-14 13:03:09,305 : INFO : PROGRESS: at sentence #70000, processed 1144759 words, keeping 143321 word types\n",
      "2018-10-14 13:03:09,362 : INFO : PROGRESS: at sentence #80000, processed 1302619 words, keeping 154734 word types\n",
      "2018-10-14 13:03:09,423 : INFO : PROGRESS: at sentence #90000, processed 1465448 words, keeping 165946 word types\n",
      "2018-10-14 13:03:09,490 : INFO : PROGRESS: at sentence #100000, processed 1622592 words, keeping 176420 word types\n",
      "2018-10-14 13:03:09,550 : INFO : PROGRESS: at sentence #110000, processed 1781965 words, keeping 188202 word types\n",
      "2018-10-14 13:03:09,607 : INFO : PROGRESS: at sentence #120000, processed 1935355 words, keeping 198206 word types\n",
      "2018-10-14 13:03:09,677 : INFO : PROGRESS: at sentence #130000, processed 2094818 words, keeping 207824 word types\n",
      "2018-10-14 13:03:09,739 : INFO : PROGRESS: at sentence #140000, processed 2254406 words, keeping 216851 word types\n",
      "2018-10-14 13:03:09,805 : INFO : PROGRESS: at sentence #150000, processed 2415368 words, keeping 225189 word types\n",
      "2018-10-14 13:03:09,863 : INFO : PROGRESS: at sentence #160000, processed 2563945 words, keeping 233083 word types\n",
      "2018-10-14 13:03:09,923 : INFO : PROGRESS: at sentence #170000, processed 2722052 words, keeping 241913 word types\n",
      "2018-10-14 13:03:09,975 : INFO : PROGRESS: at sentence #180000, processed 2877801 words, keeping 250381 word types\n",
      "2018-10-14 13:03:10,035 : INFO : PROGRESS: at sentence #190000, processed 3043652 words, keeping 259214 word types\n",
      "2018-10-14 13:03:10,096 : INFO : PROGRESS: at sentence #200000, processed 3207579 words, keeping 267821 word types\n",
      "2018-10-14 13:03:10,158 : INFO : PROGRESS: at sentence #210000, processed 3360065 words, keeping 275715 word types\n",
      "2018-10-14 13:03:10,222 : INFO : PROGRESS: at sentence #220000, processed 3527065 words, keeping 283402 word types\n",
      "2018-10-14 13:03:10,307 : INFO : PROGRESS: at sentence #230000, processed 3682274 words, keeping 289997 word types\n",
      "2018-10-14 13:03:10,408 : INFO : collected 297835 word types from a corpus of 3849457 raw words and 239983 sentences\n",
      "2018-10-14 13:03:10,410 : INFO : Loading a fresh vocabulary\n",
      "2018-10-14 13:03:11,460 : INFO : effective_min_count=1 retains 297835 unique words (100% of original 297835, drops 0)\n",
      "2018-10-14 13:03:11,460 : INFO : effective_min_count=1 leaves 3849457 word corpus (100% of original 3849457, drops 0)\n",
      "2018-10-14 13:03:12,433 : INFO : deleting the raw counts dictionary of 297835 items\n",
      "2018-10-14 13:03:12,439 : INFO : sample=0.001 downsamples 13 most-common words\n",
      "2018-10-14 13:03:12,440 : INFO : downsampling leaves estimated 3737727 word corpus (97.1% of prior 3849457)\n",
      "2018-10-14 13:03:13,324 : INFO : estimated required memory for 297835 words and 128 dimensions: 453900540 bytes\n",
      "2018-10-14 13:03:13,325 : INFO : resetting layer weights\n",
      "2018-10-14 13:03:17,864 : INFO : training model with 3 workers on 297835 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-10-14 13:03:18,882 : INFO : EPOCH 1 - PROGRESS: at 19.89% examples, 741184 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:19,882 : INFO : EPOCH 1 - PROGRESS: at 39.69% examples, 748166 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:20,885 : INFO : EPOCH 1 - PROGRESS: at 58.41% examples, 727503 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:21,897 : INFO : EPOCH 1 - PROGRESS: at 72.37% examples, 672441 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:22,904 : INFO : EPOCH 1 - PROGRESS: at 91.87% examples, 682362 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:23,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:23,290 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:23,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:23,306 : INFO : EPOCH - 1 : training on 3849457 raw words (3737584 effective words) took 5.4s, 688247 effective words/s\n",
      "2018-10-14 13:03:24,351 : INFO : EPOCH 2 - PROGRESS: at 18.07% examples, 664879 words/s, in_qsize 4, out_qsize 1\n",
      "2018-10-14 13:03:25,364 : INFO : EPOCH 2 - PROGRESS: at 35.84% examples, 667110 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:26,374 : INFO : EPOCH 2 - PROGRESS: at 54.92% examples, 678255 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:27,381 : INFO : EPOCH 2 - PROGRESS: at 75.66% examples, 696431 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:28,398 : INFO : EPOCH 2 - PROGRESS: at 94.46% examples, 696273 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:28,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:28,673 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:28,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:28,682 : INFO : EPOCH - 2 : training on 3849457 raw words (3737734 effective words) took 5.4s, 698506 effective words/s\n",
      "2018-10-14 13:03:29,703 : INFO : EPOCH 3 - PROGRESS: at 19.89% examples, 742893 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:30,709 : INFO : EPOCH 3 - PROGRESS: at 39.44% examples, 741974 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:31,712 : INFO : EPOCH 3 - PROGRESS: at 60.36% examples, 752479 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:32,720 : INFO : EPOCH 3 - PROGRESS: at 79.51% examples, 737371 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:33,727 : INFO : EPOCH 3 - PROGRESS: at 97.32% examples, 722838 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:33,880 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:33,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:33,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:33,895 : INFO : EPOCH - 3 : training on 3849457 raw words (3737407 effective words) took 5.2s, 719222 effective words/s\n",
      "2018-10-14 13:03:34,918 : INFO : EPOCH 4 - PROGRESS: at 19.14% examples, 710472 words/s, in_qsize 4, out_qsize 1\n",
      "2018-10-14 13:03:35,928 : INFO : EPOCH 4 - PROGRESS: at 39.44% examples, 738995 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:36,937 : INFO : EPOCH 4 - PROGRESS: at 59.40% examples, 736132 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:37,951 : INFO : EPOCH 4 - PROGRESS: at 79.51% examples, 733656 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:38,961 : INFO : EPOCH 4 - PROGRESS: at 97.74% examples, 723268 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:39,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:39,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:39,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:39,065 : INFO : EPOCH - 4 : training on 3849457 raw words (3737486 effective words) took 5.2s, 724782 effective words/s\n",
      "2018-10-14 13:03:40,084 : INFO : EPOCH 5 - PROGRESS: at 18.57% examples, 690344 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:41,098 : INFO : EPOCH 5 - PROGRESS: at 36.90% examples, 689046 words/s, in_qsize 4, out_qsize 1\n",
      "2018-10-14 13:03:42,103 : INFO : EPOCH 5 - PROGRESS: at 53.97% examples, 668632 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:43,104 : INFO : EPOCH 5 - PROGRESS: at 70.15% examples, 649313 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:44,109 : INFO : EPOCH 5 - PROGRESS: at 87.05% examples, 644835 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-14 13:03:44,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:44,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:44,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:44,789 : INFO : EPOCH - 5 : training on 3849457 raw words (3737777 effective words) took 5.7s, 653938 effective words/s\n",
      "2018-10-14 13:03:45,804 : INFO : EPOCH 6 - PROGRESS: at 18.85% examples, 704335 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:46,804 : INFO : EPOCH 6 - PROGRESS: at 38.67% examples, 730093 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:47,826 : INFO : EPOCH 6 - PROGRESS: at 57.87% examples, 717348 words/s, in_qsize 4, out_qsize 1\n",
      "2018-10-14 13:03:48,842 : INFO : EPOCH 6 - PROGRESS: at 77.19% examples, 712210 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:49,854 : INFO : EPOCH 6 - PROGRESS: at 96.57% examples, 713553 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:50,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:50,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:50,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:50,014 : INFO : EPOCH - 6 : training on 3849457 raw words (3737796 effective words) took 5.2s, 716810 effective words/s\n",
      "2018-10-14 13:03:51,028 : INFO : EPOCH 7 - PROGRESS: at 20.41% examples, 761071 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:52,037 : INFO : EPOCH 7 - PROGRESS: at 41.29% examples, 774317 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:53,049 : INFO : EPOCH 7 - PROGRESS: at 60.60% examples, 752443 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:54,058 : INFO : EPOCH 7 - PROGRESS: at 76.69% examples, 708489 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:55,059 : INFO : EPOCH 7 - PROGRESS: at 96.80% examples, 717828 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:55,250 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:03:55,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:03:55,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:03:55,283 : INFO : EPOCH - 7 : training on 3849457 raw words (3737402 effective words) took 5.3s, 710352 effective words/s\n",
      "2018-10-14 13:03:56,331 : INFO : EPOCH 8 - PROGRESS: at 13.72% examples, 502359 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:03:57,343 : INFO : EPOCH 8 - PROGRESS: at 30.27% examples, 566854 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:58,354 : INFO : EPOCH 8 - PROGRESS: at 49.22% examples, 607895 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:03:59,362 : INFO : EPOCH 8 - PROGRESS: at 67.51% examples, 621864 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:04:00,376 : INFO : EPOCH 8 - PROGRESS: at 83.27% examples, 614111 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:04:01,282 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:04:01,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:04:01,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:04:01,299 : INFO : EPOCH - 8 : training on 3849457 raw words (3737615 effective words) took 6.0s, 623955 effective words/s\n",
      "2018-10-14 13:04:02,312 : INFO : EPOCH 9 - PROGRESS: at 18.57% examples, 695680 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:04:03,314 : INFO : EPOCH 9 - PROGRESS: at 37.12% examples, 700659 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:04:04,329 : INFO : EPOCH 9 - PROGRESS: at 55.83% examples, 692958 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:04:05,339 : INFO : EPOCH 9 - PROGRESS: at 75.93% examples, 702229 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:04:06,348 : INFO : EPOCH 9 - PROGRESS: at 95.10% examples, 704072 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:04:06,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:04:06,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:04:06,603 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:04:06,604 : INFO : EPOCH - 9 : training on 3849457 raw words (3737941 effective words) took 5.3s, 705702 effective words/s\n",
      "2018-10-14 13:04:07,622 : INFO : EPOCH 10 - PROGRESS: at 18.33% examples, 687923 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:04:08,623 : INFO : EPOCH 10 - PROGRESS: at 36.90% examples, 697398 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:04:09,635 : INFO : EPOCH 10 - PROGRESS: at 57.38% examples, 714011 words/s, in_qsize 5, out_qsize 0\n",
      "2018-10-14 13:04:10,648 : INFO : EPOCH 10 - PROGRESS: at 78.73% examples, 729722 words/s, in_qsize 6, out_qsize 0\n",
      "2018-10-14 13:04:11,648 : INFO : EPOCH 10 - PROGRESS: at 99.47% examples, 739794 words/s, in_qsize 2, out_qsize 1\n",
      "2018-10-14 13:04:11,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-14 13:04:11,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-14 13:04:11,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-14 13:04:11,662 : INFO : EPOCH - 10 : training on 3849457 raw words (3737467 effective words) took 5.0s, 741639 effective words/s\n",
      "2018-10-14 13:04:11,662 : INFO : training on a 38494570 raw words (37376209 effective words) took 53.8s, 694756 effective words/s\n"
     ]
    }
   ],
   "source": [
    "sentenses = open('data/news.txt', encoding='utf-8').read().split('*')\n",
    "sentenses = [s.strip().split() for s in sentenses]\n",
    "model = gensim.models.Word2Vec(sentenses, size=128, iter=10, min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-10-14 13:04:11,721 : INFO : precomputing L2-norms of word weight vectors\n",
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "2018-10-14 13:04:12,482 : INFO : syntactic evaluation: 0.0% (0/132)\n",
      "2018-10-14 13:04:12,482 : INFO : total: 0.0% (0/132)\n",
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n",
      "  \n",
      "2018-10-14 13:04:13,249 : INFO : semantic word embedding: 7.0% (13/185)\n",
      "2018-10-14 13:04:13,251 : INFO : total: 7.0% (13/185)\n"
     ]
    }
   ],
   "source": [
    "result = model.accuracy('data/syntax.txt')\n",
    "result = model.accuracy('data/semantic.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-14 13:04:59,602 : INFO : collecting all words and their counts\n",
      "2018-10-14 13:04:59,603 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-14 13:04:59,656 : INFO : PROGRESS: at sentence #10000, processed 150787 words, keeping 38040 word types\n",
      "2018-10-14 13:04:59,732 : INFO : PROGRESS: at sentence #20000, processed 309265 words, keeping 61588 word types\n",
      "2018-10-14 13:04:59,780 : INFO : PROGRESS: at sentence #30000, processed 477795 words, keeping 81867 word types\n",
      "2018-10-14 13:04:59,850 : INFO : PROGRESS: at sentence #40000, processed 647737 words, keeping 100652 word types\n",
      "2018-10-14 13:04:59,906 : INFO : PROGRESS: at sentence #50000, processed 805941 words, keeping 116075 word types\n",
      "2018-10-14 13:04:59,956 : INFO : PROGRESS: at sentence #60000, processed 967897 words, keeping 129675 word types\n",
      "2018-10-14 13:05:00,039 : INFO : PROGRESS: at sentence #70000, processed 1144759 words, keeping 143321 word types\n",
      "2018-10-14 13:05:00,095 : INFO : PROGRESS: at sentence #80000, processed 1302619 words, keeping 154734 word types\n",
      "2018-10-14 13:05:00,164 : INFO : PROGRESS: at sentence #90000, processed 1465448 words, keeping 165946 word types\n",
      "2018-10-14 13:05:00,225 : INFO : PROGRESS: at sentence #100000, processed 1622592 words, keeping 176420 word types\n",
      "2018-10-14 13:05:00,290 : INFO : PROGRESS: at sentence #110000, processed 1781965 words, keeping 188202 word types\n",
      "2018-10-14 13:05:00,344 : INFO : PROGRESS: at sentence #120000, processed 1935355 words, keeping 198206 word types\n",
      "2018-10-14 13:05:00,394 : INFO : PROGRESS: at sentence #130000, processed 2094818 words, keeping 207824 word types\n",
      "2018-10-14 13:05:00,461 : INFO : PROGRESS: at sentence #140000, processed 2254406 words, keeping 216851 word types\n",
      "2018-10-14 13:05:00,520 : INFO : PROGRESS: at sentence #150000, processed 2415368 words, keeping 225189 word types\n",
      "2018-10-14 13:05:00,567 : INFO : PROGRESS: at sentence #160000, processed 2563945 words, keeping 233083 word types\n",
      "2018-10-14 13:05:00,624 : INFO : PROGRESS: at sentence #170000, processed 2722052 words, keeping 241913 word types\n",
      "2018-10-14 13:05:00,708 : INFO : PROGRESS: at sentence #180000, processed 2877801 words, keeping 250381 word types\n",
      "2018-10-14 13:05:00,799 : INFO : PROGRESS: at sentence #190000, processed 3043652 words, keeping 259214 word types\n",
      "2018-10-14 13:05:00,892 : INFO : PROGRESS: at sentence #200000, processed 3207579 words, keeping 267821 word types\n",
      "2018-10-14 13:05:00,945 : INFO : PROGRESS: at sentence #210000, processed 3360065 words, keeping 275715 word types\n",
      "2018-10-14 13:05:01,010 : INFO : PROGRESS: at sentence #220000, processed 3527065 words, keeping 283402 word types\n",
      "2018-10-14 13:05:01,056 : INFO : PROGRESS: at sentence #230000, processed 3682274 words, keeping 289997 word types\n",
      "2018-10-14 13:05:01,110 : INFO : collected 297835 word types from a corpus of 3849457 raw words and 239983 sentences\n",
      "2018-10-14 13:05:01,110 : INFO : Loading a fresh vocabulary\n",
      "2018-10-14 13:05:02,115 : INFO : effective_min_count=1 retains 297835 unique words (100% of original 297835, drops 0)\n",
      "2018-10-14 13:05:02,116 : INFO : effective_min_count=1 leaves 3849457 word corpus (100% of original 3849457, drops 0)\n",
      "2018-10-14 13:05:03,126 : INFO : deleting the raw counts dictionary of 297835 items\n",
      "2018-10-14 13:05:03,131 : INFO : sample=0.001 downsamples 13 most-common words\n",
      "2018-10-14 13:05:03,132 : INFO : downsampling leaves estimated 3737727 word corpus (97.1% of prior 3849457)\n",
      "2018-10-14 13:05:03,986 : INFO : estimated required memory for 297835 words and 128 dimensions: 453900540 bytes\n",
      "2018-10-14 13:05:03,986 : INFO : resetting layer weights\n",
      "2018-10-14 13:05:08,314 : INFO : training model with 3 workers on 297835 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-10-14 13:05:08,315 : INFO : training on a 0 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-10-14 13:05:08,316 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2018-10-14 13:05:08,431 : INFO : precomputing L2-norms of word weight vectors\n",
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "2018-10-14 13:05:09,562 : INFO : syntactic evaluation: 0.0% (0/132)\n",
      "2018-10-14 13:05:09,563 : INFO : total: 0.0% (0/132)\n",
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "2018-10-14 13:05:10,222 : INFO : semantic word embedding: 7.0% (13/185)\n",
      "2018-10-14 13:05:10,223 : INFO : total: 7.0% (13/185)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = gensim.models.Word2Vec(sentenses, size=128, iter=0, min_count=1)\n",
    "model.wv.init_sims()\n",
    "model1.wv.init_sims()\n",
    "for gindex in range(len(model.wv.index2word)):\n",
    "    gword = model.wv.index2word[gindex]\n",
    "    model1.wv.vectors_norm[gindex] = model.wv.vectors_norm[gindex]\n",
    "\n",
    "result = model1.accuracy('data/syntax.txt')\n",
    "result = model1.accuracy('data/semantic.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
