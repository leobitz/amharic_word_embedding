{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 1000\n",
    "random.seed(seed_val)\n",
    "import numpy as np\n",
    "np.random.seed(seed_val)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_val)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, TimeDistributed, SimpleRNN\n",
    "from keras.layers import Concatenate, Flatten\n",
    "from keras.layers import GRU, Conv2D, MaxPooling2D, AveragePooling2D, AvgPool2D, MaxPool1D\n",
    "from keras.layers import Input, Reshape, Dot, Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from data_handle import *\n",
    "from gensim_wrapper import *\n",
    "from utils import *\n",
    "import gensim\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_word_chars, n_consonant, n_vowels, n_units):\n",
    "    inputs = []\n",
    "    denses = []\n",
    "    char_emb_size = 10\n",
    "#     n_units = max_word_chars * char_emb_size\n",
    "    for i in range(max_word_chars):\n",
    "        name =  'char_' + str(i)\n",
    "        char_input = Input(shape=((n_consonant + n_vowels), ),name=name)\n",
    "        name =  'dense_' + str(i)\n",
    "        x = Dense(char_emb_size, activation='relu', name=name)(char_input)\n",
    "        inputs.append(char_input)\n",
    "        x = Reshape((char_emb_size, 1))(x)\n",
    "        denses.append(x)\n",
    "        \n",
    "    x = Concatenate(axis=2)(denses)\n",
    "    x = Reshape((10, 13, 1))(x)\n",
    "    x = Conv2D(16, (5, 5), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(3, 3)(x)\n",
    "    x = Flatten()(x)\n",
    "    state_h = Dense(100, activation='linear', name='state_h')(x)\n",
    "    \n",
    "    consonant_decoder_inputs = Input(shape=(None, n_consonant), name=\"target_consonant\")\n",
    "    consonant_decoder_gru = GRU(n_units, return_sequences=True, return_state=True,  name=\"consonant_decoder_gru\")\n",
    "    consonant_decoder_outputs, _= consonant_decoder_gru(consonant_decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    vowel_decoder_inputs = Input(shape=(None, n_vowels), name=\"vowel_input\")\n",
    "    vowel_decoder_gru = GRU(n_units, return_sequences=True, return_state=True, name=\"vowl_decoder_gru\")\n",
    "    vowel_decoder_outputs, _= vowel_decoder_gru(vowel_decoder_inputs, initial_state=state_h)\n",
    "\n",
    "    consonant_decoder_dense = Dense(n_consonant, activation='softmax', name=\"consonant_output\")\n",
    "    consonant_decoder_outputs = consonant_decoder_dense(consonant_decoder_outputs)\n",
    "    \n",
    "    vowel_decoder_dense = Dense(n_vowels, activation='softmax', name=\"vowel_output\")\n",
    "    vowel_decoder_outputs = vowel_decoder_dense(vowel_decoder_outputs)\n",
    "    \n",
    "    main_model = Model(inputs + [consonant_decoder_inputs, vowel_decoder_inputs], [consonant_decoder_outputs, vowel_decoder_outputs])\n",
    "    \n",
    "    encoder_model = Model(inputs, state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    \n",
    "    consonant_decoder_outputs, state_h= consonant_decoder_gru(consonant_decoder_inputs, initial_state=decoder_state_input_h)\n",
    "    consonant_decoder_outputs = consonant_decoder_dense(consonant_decoder_outputs)\n",
    "    \n",
    "    vowel_decoder_outputs, state_h= vowel_decoder_gru(vowel_decoder_inputs, initial_state=decoder_state_input_h)\n",
    "    vowel_decoder_outputs = vowel_decoder_dense(vowel_decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model([consonant_decoder_inputs, vowel_decoder_inputs, decoder_state_input_h], [consonant_decoder_outputs, vowel_decoder_outputs, state_h])\n",
    "\n",
    "    return main_model, encoder_model, decoder_model\n",
    "\n",
    "    \n",
    "def one_hot_sep(con, con_max, vow, vow_max):\n",
    "    con_vec = np.zeros((con_max, ))\n",
    "    con_vec[con] = 1\n",
    "    vow_vec = np.zeros((vow_max, ))\n",
    "    vow_vec[vow] = 1\n",
    "    return con_vec, vow_vec\n",
    "    \n",
    "def decode_multi_sequence(model, char2tup, tup2char, state, n_consonant, n_vowels):\n",
    "    con, vow = char2tup['&']\n",
    "    con_vec, vow_vec = one_hot_sep(con, n_consonant, vow, n_vowels) \n",
    "    con_vec = con_vec.reshape((1, 1, -1))\n",
    "    vow_vec = vow_vec.reshape((1, 1, -1))\n",
    "    decoded_chars = []\n",
    "    for i in range(13):\n",
    "        con_vec, vow_vec, state = model.predict([con_vec, vow_vec, state])\n",
    "        new_con_vec = np.zeros_like(con_vec)\n",
    "        new_con_vec[0, 0, np.argmax(con_vec[0, 0, :])] = 1\n",
    "        new_vow_vec = np.zeros_like(vow_vec)\n",
    "        new_vow_vec[0, 0, np.argmax(vow_vec[0, 0, :])] = 1\n",
    "        con_vec, vow_vec = new_con_vec, new_vow_vec\n",
    "        name = \"{0}-{1}\".format(np.argmax(con_vec[0, 0, :]), np.argmax(vow_vec[0, 0, :]))\n",
    "        try:\n",
    "            char = tup2char[name]\n",
    "        except:\n",
    "            char = ' '\n",
    "        decoded_chars += [char]\n",
    "    \n",
    "    return decoded_chars\n",
    "\n",
    "def get_proper_input(buffer):\n",
    "    np_inputs = [np.zeros((len(buffer), 50)) for i in range(13)]\n",
    "    for i in range(len(buffer)):\n",
    "        chars = buffer[i]\n",
    "        for j in range(len(chars)):\n",
    "            np_inputs[j][i] = chars[j]\n",
    "        \n",
    "    return np_inputs\n",
    "\n",
    "def pred_embeddings_multi(vocab, encoder, char2tup):\n",
    "    embeddings = np.ndarray((len(vocab), embed_size))\n",
    "    i = 0\n",
    "    buffer = []\n",
    "    buffer_size = 10000\n",
    "    for wi, word in enumerate(vocab):\n",
    "        word = int2word[word2int[word]]\n",
    "        buffer.append(word)\n",
    "        if len(buffer) == buffer_size or len(vocab) - wi < buffer_size:\n",
    "            buffer_np = word2vec_single(char2tup, buffer, n_chars, n_consonant, n_vowel)\n",
    "            result = encoder.predict(buffer_np)\n",
    "            embeddings[i:i+len(buffer)] = result\n",
    "            i += len(buffer)\n",
    "            buffer = []\n",
    "            if i % (4 * buffer_size) == 0:\n",
    "                print(\"Predicting: {0:.2f}%\".format((i * 100.0 / len(vocab))))\n",
    "                \n",
    "    print(\"finished\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read_file()\n",
    "vocab, word2int, int2word = build_vocab(words)\n",
    "int_words = words_to_ints(word2int, words)\n",
    "word2freq = get_frequency(words, word2int, int2word)\n",
    "char2int, int2char, char2tup, tup2char, n_consonant, n_vowel = build_charset()\n",
    "ns_unigrams = ns_sample(word2freq, word2int, int2word, .75)\n",
    "n_chars = 11 + 2 \n",
    "n_features = len(char2int)\n",
    "batch_size = 300\n",
    "embed_size = 100\n",
    "skip_window = 1\n",
    "\n",
    "\n",
    "n_batches = len(vocab)  // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_0 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_1 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_2 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_3 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_4 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_5 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_6 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_7 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_8 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_9 (InputLayer)             (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_10 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_11 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_12 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 10)           510         char_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           510         char_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           510         char_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           510         char_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           510         char_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           510         char_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           510         char_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           510         char_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           510         char_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           510         char_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           510         char_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10)           510         char_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           510         char_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 1)        0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 1)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 1)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 1)        0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 1)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 1)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 1)        0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 10, 1)        0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 10, 1)        0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 10, 1)        0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 10, 1)        0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 10, 1)        0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 10, 1)        0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 13)       0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 10, 13, 1)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 10, 13, 16)   416         reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 3, 4, 16)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 192)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "target_consonant (InputLayer)   (None, None, 40)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "state_h (Dense)                 (None, 100)          19300       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "vowel_input (InputLayer)        (None, None, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "consonant_decoder_gru (GRU)     [(None, None, 100),  42300       target_consonant[0][0]           \n",
      "                                                                 state_h[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vowl_decoder_gru (GRU)          [(None, None, 100),  33300       vowel_input[0][0]                \n",
      "                                                                 state_h[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "consonant_output (Dense)        (None, None, 40)     4040        consonant_decoder_gru[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vowel_output (Dense)            (None, None, 10)     1010        vowl_decoder_gru[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 106,996\n",
      "Trainable params: 106,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del multi_train\n",
    "    del multi_enc\n",
    "    del multi_dec\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n",
    "multi_train, multi_enc, multi_dec = create_model(n_chars, n_consonant, n_vowel, embed_size)\n",
    "adam = keras.optimizers.Nadam(.001)\n",
    "multi_train.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "multi_gen = generate_word_images_multi_v6(vocab, char2tup, batch_size, n_consonant, n_vowel)\n",
    "multi_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "992/992 [==============================] - 98s 99ms/step - loss: 1.2481 - consonant_output_loss: 0.8278 - vowel_output_loss: 0.4203 - consonant_output_acc: 0.7744 - vowel_output_acc: 0.8586\n",
      "Epoch 2/4\n",
      "992/992 [==============================] - 91s 92ms/step - loss: 0.3752 - consonant_output_loss: 0.2693 - vowel_output_loss: 0.1059 - consonant_output_acc: 0.9326 - vowel_output_acc: 0.9699\n",
      "Epoch 3/4\n",
      "992/992 [==============================] - 91s 91ms/step - loss: 0.1129 - consonant_output_loss: 0.0770 - vowel_output_loss: 0.0359 - consonant_output_acc: 0.9862 - vowel_output_acc: 0.9935 1s - loss: 0.1134 - consonant_output_loss: 0.0771 - vowel_output_loss: 0.0363 - consonant_output_acc: 0.9861 - vow\n",
      "Epoch 4/4\n",
      "992/992 [==============================] - 92s 93ms/step - loss: 0.0504 - consonant_output_loss: 0.0316 - vowel_output_loss: 0.0188 - consonant_output_acc: 0.9951 - vowel_output_acc: 0.9969 0s - loss: 0.0503 - consonant_output_loss: 0.0315 - vowel_output_loss: 0.0188 - consonant_output_acc: 0.9952 - vowel_output_ac\n"
     ]
    }
   ],
   "source": [
    "history = multi_train.fit_generator(multi_gen, steps_per_epoch=n_batches, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 13.43%\n",
      "Predicting: 26.86%\n",
      "Predicting: 40.29%\n",
      "Predicting: 53.72%\n",
      "Predicting: 67.15%\n",
      "Predicting: 80.58%\n",
      "Predicting: 94.01%\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "embeddings = pred_embeddings_multi(vocab, multi_enc, char2tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'syntactic': 0.0, 'semantic': 0.0, 'total': 0.0, 'pick-one-out': 28.440366972477065}\n",
      "{'syntactic': 0.0, 'semantic': 0.0, 'total': 0.0, 'pick-one-out': 42.20183486238532}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(word2int, embeddings, embed_size=100))\n",
    "print(evaluate(word2int, normalize(embeddings), embed_size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
