{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import Concatenate, Flatten\n",
    "from keras.layers import GRU, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Reshape, Dot, Add\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from data_handle import *\n",
    "from gensim_wrapper import *\n",
    "from utils import *\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(n_input, n_output, n_enc_units, n_dec_units):\n",
    "    root_word_input = Input(shape=(13, 309, 1), name=\"root_word_input\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    X = Dropout(.2)(x)\n",
    "    x = Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Flatten()(x)\n",
    "#     x = Dense(300, activation='relu')(x)\n",
    "    X = Dropout(.2)(x)\n",
    "    state_h = Dense(n_dec_units, activation='linear')(x)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, 309), name=\"target_word_input\")\n",
    "    decoder_gru = GRU(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(309, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs], decoder_outputs)\n",
    "    encoder_model = Model(root_word_input, state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_multi(n_chars, n_consonant, n_vowels, n_units):\n",
    "    root_word_input = Input(shape=(n_chars, (n_consonant + n_vowels), 1), name=\"root_word_input\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    X = Dropout(.2)(x)\n",
    "    x = Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Flatten()(x)\n",
    "#     x = Dense(300, activation='relu')(x)\n",
    "#     X = Dropout(.2)(x)\n",
    "    state_h = Dense(n_units, activation='linear')(x)\n",
    "    \n",
    "    consonant_decoder_inputs = Input(shape=(None, n_consonant), name=\"target_consonant\")\n",
    "    consonant_decoder_gru = GRU(n_units, return_sequences=True, return_state=True, name=\"consonant_decoder_gru\")\n",
    "    consonant_decoder_outputs, _= consonant_decoder_gru(consonant_decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    vowel_decoder_inputs = Input(shape=(None, n_vowels), name=\"vowel_input\")\n",
    "    vowel_decoder_gru = GRU(n_units, return_sequences=True, return_state=True, name=\"vowl_decoder_gru\")\n",
    "    vowel_decoder_outputs, _= vowel_decoder_gru(vowel_decoder_inputs, initial_state=state_h)\n",
    "    print(vowel_decoder_outputs.shape, consonant_decoder_outputs.shape)\n",
    "    x = Concatenate(axis=1)([vowel_decoder_outputs, consonant_decoder_outputs])\n",
    "    print(x.shape)\n",
    "    consonant_decoder_dense = Dense(n_consonant, activation='softmax', name=\"consonant_output\")\n",
    "    consonant_decoder_outputs = consonant_decoder_dense(x)\n",
    "    \n",
    "    vowel_decoder_dense = Dense(n_vowels, activation='softmax', name=\"vowel_output\")\n",
    "    vowel_decoder_outputs = vowel_decoder_dense(x)\n",
    "    \n",
    "    main_model = Model([root_word_input, consonant_decoder_inputs, vowel_decoder_inputs], [consonant_decoder_outputs, vowel_decoder_outputs])\n",
    "    \n",
    "    encoder_model = Model(root_word_input, state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    \n",
    "    consonant_decoder_outputs, state_h= consonant_decoder_gru(consonant_decoder_inputs, initial_state=decoder_state_input_h)\n",
    "    consonant_decoder_outputs = consonant_decoder_dense(consonant_decoder_outputs)\n",
    "    \n",
    "    vowel_decoder_outputs, state_h= vowel_decoder_gru(vowel_decoder_inputs, initial_state=decoder_state_input_h)\n",
    "    vowel_decoder_outputs = vowel_decoder_dense(vowel_decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model([consonant_decoder_inputs, vowel_decoder_inputs, decoder_state_input_h], [consonant_decoder_outputs, vowel_decoder_outputs, state_h])\n",
    "\n",
    "    return main_model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_multi_v2(n_chars, n_char_class, n_consonant, n_vowels, n_units):\n",
    "    root_word_input = Input(shape=(n_chars, (n_consonant + n_vowels), 1), name=\"root_word_input\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    X = Dropout(.2)(x)\n",
    "    x = Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Flatten()(x)\n",
    "#     x = Dense(300, activation='relu')(x)\n",
    "#     X = Dropout(.2)(x)\n",
    "    state_h = Dense(n_units, activation='linear')(x)\n",
    "    \n",
    "    consonant_decoder_inputs = Input(shape=(None, n_consonant), name=\"target_consonant\")\n",
    "    consonant_decoder_gru = GRU(n_units, return_sequences=True, return_state=True, name=\"consonant_decoder_gru\")\n",
    "    consonant_decoder_outputs, _= consonant_decoder_gru(consonant_decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    vowel_decoder_inputs = Input(shape=(None, n_vowels), name=\"vowel_input\")\n",
    "    vowel_decoder_gru = GRU(n_units, return_sequences=True, return_state=True, name=\"vowl_decoder_gru\")\n",
    "    vowel_decoder_outputs, _= vowel_decoder_gru(vowel_decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoders_outputs = Concatenate(axis=1)([consonant_decoder_outputs, vowel_decoder_outputs])\n",
    "  \n",
    "    decoder_dense = Dense(n_char_class, activation='softmax', name=\"decoder_output\")\n",
    "    decoders_outputs = decoder_dense(decoders_outputs)\n",
    "    \n",
    "    main_model = Model([root_word_input, consonant_decoder_inputs, vowel_decoder_inputs], decoders_outputs)\n",
    "    encoder_model = Model(root_word_input, state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    \n",
    "    consonant_decoder_outputs, state_h= consonant_decoder_gru(consonant_decoder_inputs, initial_state=decoder_state_input_h)\n",
    "    vowel_decoder_outputs, state_h= vowel_decoder_gru(vowel_decoder_inputs, initial_state=decoder_state_input_h)\n",
    "    \n",
    "    decoders_outputs = Concatenate(axis=1)([consonant_decoder_outputs, vowel_decoder_outputs])\n",
    "    decoders_outputs = decoder_dense(decoders_outputs)\n",
    "    \n",
    "    decoder_model = Model([consonant_decoder_inputs, vowel_decoder_inputs, decoder_state_input_h], [decoders_outputs, state_h])\n",
    "    \n",
    "    return main_model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model2(n_input, n_output, n_enc_units, n_dec_units):\n",
    "    root_word_input = Input(shape=(13, 309, 1), name=\"root_word_input\")\n",
    "    word_feature = Input(shape=(128,), name=\"word_feature\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    X = Dropout(.2)(x)\n",
    "    x = Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='linear')(x)\n",
    "#     X = Dropout(.2)(x)\n",
    "    x = Add()([x, word_feature])\n",
    "    state_h = Dense(n_dec_units, activation='linear')(x)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, 309), name=\"target_word_input\")\n",
    "    decoder_gru = GRU(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(309, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs, word_feature], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, word_feature], state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(model, int2char, state):\n",
    "    target_seq = np.zeros([1, 1, 309])\n",
    "    target_seq[0, 0, char2int['&']] = 1\n",
    "    decoded_chars = []\n",
    "    for i in range(13):\n",
    "        target_seq, state = model.predict([target_seq, state])\n",
    "        index = np.argmax(target_seq.flatten())\n",
    "        char = int2char[index]\n",
    "        decoded_chars += [char]\n",
    "        \n",
    "#         target_seq = np.zeros([1, 1, 309])\n",
    "#         target_seq[0, 0, index] = 1\n",
    "    return decoded_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_sep(con, con_max, vow, vow_max):\n",
    "    con_vec = np.zeros((con_max, ))\n",
    "    con_vec[con] = 1\n",
    "    vow_vec = np.zeros((vow_max, ))\n",
    "    vow_vec[vow] = 1\n",
    "    return con_vec, vow_vec\n",
    "    \n",
    "def decode_multi_sequence(model, char2tup, tup2char, state, n_consonant, n_vowels):\n",
    "    con, vow = char2tup['&']\n",
    "    con_vec, vow_vec = one_hot_sep(con, n_consonant, vow, n_vowels) \n",
    "    con_vec = con_vec.reshape((1, 1, -1))\n",
    "    vow_vec = vow_vec.reshape((1, 1, -1))\n",
    "#     target_seq = np.concatenate([con_vec, vow_vec])\n",
    "    decoded_chars = []\n",
    "    for i in range(13):\n",
    "        con_vec, vow_vec, state = model.predict([con_vec, vow_vec, state])\n",
    "#         target_seq = np.concatenate([con_vec, vow_vec])\n",
    "        new_con_vec = np.zeros_like(con_vec)\n",
    "        new_con_vec[0, 0, np.argmax(con_vec[0, 0, :])] = 1\n",
    "        new_vow_vec = np.zeros_like(vow_vec)\n",
    "        new_vow_vec[0, 0, np.argmax(vow_vec[0, 0, :])] = 1\n",
    "        con_vec, vow_vec = new_con_vec, new_vow_vec\n",
    "        name = \"{0}-{1}\".format(np.argmax(con_vec[0, 0, :]), np.argmax(vow_vec[0, 0, :]))\n",
    "        try:\n",
    "            char = tup2char[name]\n",
    "        except:\n",
    "            char = ' '\n",
    "        decoded_chars += [char]\n",
    "    \n",
    "    return decoded_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(input_size, output_size, embed_size):\n",
    "    context_word = Input(shape=(input_size,), name=\"context_word\")\n",
    "    x = Dense(256, activation='relu')(context_word)\n",
    "    embeding = Dense(embed_size, activation='tanh')(x)\n",
    "    target_word = Dense(output_size, activation='relu')(embeding)\n",
    "    model = Model(context_word, target_word)\n",
    "    em_model = Model(context_word, embeding)\n",
    "    return model, em_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_loss(yTrue, yPred):\n",
    "    loss = K.sum(K.square(yTrue - yPred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model2(input_size, output_size, embed_size):\n",
    "    context_word = Input(shape=(input_size,), name=\"context_word\")\n",
    "    target_word = Input(shape=(input_size,), name=\"target_word\")\n",
    "    \n",
    "    layer1 = Dense(200, activation='tanh')\n",
    "    layer2 = Dense(200, activation='tanh')\n",
    "    \n",
    "    x = layer1(context_word)\n",
    "    y = layer1(target_word)\n",
    "#     y = layer2(y)\n",
    "    cosine_sim = Dot(normalize=True, axes=1)([x, y])\n",
    "#     z = Concatenate(axis=1)([x, y])\n",
    "#     z = Dense(20, activation='tanh')(z)\n",
    "    \n",
    "#     output = Dense(1, activation='tanh')(z)\n",
    "    model = Model([context_word, target_word], cosine_sim)\n",
    "    \n",
    "    con_model = Model(context_word, x)\n",
    "    tar_model = Model(target_word, y)\n",
    "    \n",
    "    return model, con_model, tar_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeder3(input_size, embed_size):\n",
    "    context_word = Input(shape=(input_size,), name=\"context_word\")\n",
    "    \n",
    "    x = Dense(embed_size, activation='tanh')(context_word)\n",
    "    y = Dense(embed_size, activation='tanh')(x)\n",
    "    \n",
    "    model = Model(context_word, y)\n",
    "    em_model = Model(context_word, x)\n",
    "    return model, em_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model3(input_size, output_size, embed_size):\n",
    "    left_word = Input(shape=(input_size,), name=\"left_word\")\n",
    "    right_word = Input(shape=(input_size,), name=\"right_word\")\n",
    "    \n",
    "    layer1 = Dense(128, activation='relu')\n",
    "    layer2 = Dense(128, activation='linear')\n",
    "    \n",
    "    left = layer1(left_word)\n",
    "    right = layer1(right_word)\n",
    "    \n",
    "    left = layer2(left)\n",
    "    right = layer2(right)\n",
    "    \n",
    "    x = Concatenate(axis=1)([left, right])\n",
    "    x = Dense(embed_size, activation='tanh')(x)\n",
    "    \n",
    "    model = Model([left_word, right_word], x)\n",
    "    con_model = Model(left_word, left)\n",
    "    tar_model = Model(right_word, right)\n",
    "    \n",
    "    return model, con_model, tar_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(final_embedding, word2int, embed_size):\n",
    "    gensim = GensimWrapper(embed_size, 0, log=False)\n",
    "    gensim.set_embeddings(word2int, final_embedding)\n",
    "    result = gensim.evaluate()\n",
    "    for key in result:\n",
    "        print(\"{0}: {1:.2f}%\".format(key, result[key]), end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(embeddings):\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    return embeddings / norms\n",
    "\n",
    "def normalize2(embeddings):\n",
    "    maxes = np.max(np.abs(embeddings), axis=1, keepdims=True)\n",
    "    return embeddings / maxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = read_file()\n",
    "vocab, word2int, int2word = build_vocab(words)\n",
    "int_words = words_to_ints(word2int, words)\n",
    "word2freq = get_frequency(words, word2int, int2word)\n",
    "char2int, int2char, char2tup, tup2char, n_consonant, n_vowel = build_charset()\n",
    "ns_unigrams = ns_sample(word2freq, word2int, int2word, .75)\n",
    "n_chars = 11 + 2 \n",
    "n_features = len(char2int)\n",
    "batch_size = 120\n",
    "embed_size = 128\n",
    "skip_window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gen = generate_word_images_multi(words, char2tup, batch_size, n_consonant, n_vowel)\n",
    "# multi_gen = generate_word_images_multi_v2(words, char2int, char2tup, batch_size, n_consonant, n_vowel)\n",
    "\n",
    "# [x1, x2, x3], y = next(multi_gen)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 128) (?, ?, 128)\n",
      "(?, ?, 128)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "root_word_input (InputLayer)    (None, 13, 50, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 50, 16)   160         root_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 6, 25, 16)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 6, 25, 8)     1160        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 3, 12, 8)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 288)          0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vowel_input (InputLayer)        (None, None, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          36992       flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "target_consonant (InputLayer)   (None, None, 40)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vowl_decoder_gru (GRU)          [(None, None, 128),  53376       vowel_input[0][0]                \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "consonant_decoder_gru (GRU)     [(None, None, 128),  64896       target_consonant[0][0]           \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 128)    0           vowl_decoder_gru[0][0]           \n",
      "                                                                 consonant_decoder_gru[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "consonant_output (Dense)        (None, None, 40)     5160        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "vowel_output (Dense)            (None, None, 10)     1290        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 163,034\n",
      "Trainable params: 163,034\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi_train, multi_enc, multi_dec = conv_model_multi(n_chars, n_consonant, n_vowel, embed_size)\n",
    "adam = keras.optimizers.Nadam(0.001)\n",
    "multi_train.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "multi_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_train2, multi_enc2, multi_dec2 = conv_model_multi_v2(n_chars, len(char2int), n_consonant, n_vowel, embed_size)\n",
    "# adam = keras.optimizers.Nadam(0.001)\n",
    "# multi_train2.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "# multi_train2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [120,13] vs. [120,26]\n\t [[Node: metrics_3/acc/Equal = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](metrics_3/acc/ArgMax, metrics_3/acc/ArgMax_1)]]\n\t [[Node: metrics_3/acc/Mean/_481 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3647_metrics_3/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'metrics_3/acc/Equal', defined at:\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-f8c5b46d54b9>\", line 3, in <module>\n    multi_train.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\", line 934, in compile\n    handle_metrics(output_metrics)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\", line 913, in handle_metrics\n    mask=masks[i])\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\metrics.py\", line 32, in categorical_accuracy\n    K.argmax(y_pred, axis=-1)),\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1579, in equal\n    return tf.equal(x, y)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2862, in equal\n    \"Equal\", x=x, y=y, name=name)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [120,13] vs. [120,26]\n\t [[Node: metrics_3/acc/Equal = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](metrics_3/acc/ArgMax, metrics_3/acc/ArgMax_1)]]\n\t [[Node: metrics_3/acc/Mean/_481 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3647_metrics_3/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [120,13] vs. [120,26]\n\t [[Node: metrics_3/acc/Equal = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](metrics_3/acc/ArgMax, metrics_3/acc/ArgMax_1)]]\n\t [[Node: metrics_3/acc/Mean/_481 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3647_metrics_3/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-60c8edf557bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [120,13] vs. [120,26]\n\t [[Node: metrics_3/acc/Equal = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](metrics_3/acc/ArgMax, metrics_3/acc/ArgMax_1)]]\n\t [[Node: metrics_3/acc/Mean/_481 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3647_metrics_3/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'metrics_3/acc/Equal', defined at:\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-f8c5b46d54b9>\", line 3, in <module>\n    multi_train.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\", line 934, in compile\n    handle_metrics(output_metrics)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\", line 913, in handle_metrics\n    mask=masks[i])\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\metrics.py\", line 32, in categorical_accuracy\n    K.argmax(y_pred, axis=-1)),\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1579, in equal\n    return tf.equal(x, y)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2862, in equal\n    \"Equal\", x=x, y=y, name=name)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [120,13] vs. [120,26]\n\t [[Node: metrics_3/acc/Equal = Equal[T=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](metrics_3/acc/ArgMax, metrics_3/acc/ArgMax_1)]]\n\t [[Node: metrics_3/acc/Mean/_481 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3647_metrics_3/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "n_batches = len(vocab) // batch_size\n",
    "history = multi_train.fit_generator(multi_gen, steps_per_epoch=n_batches, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = vocab[:int(len(vocab) * .8)]\n",
    "test_vocab = vocab[int(len(vocab) * .8):]\n",
    "gen = generate_word_images_feat(vocab, word2int, char2int, sem_embed, batch_size)\n",
    "# gen2 = generate_batch_image_v3(words, word2int, char2int, batch_size, skip_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, infenc, infdec = conv_model2(13, 13, embed_size, embed_size)\n",
    "adam = keras.optimizers.Nadam(0.001)\n",
    "# train.compile(optimizer=adam, loss='mse')\n",
    "train.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "# train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batches = len(vocab) // batch_size\n",
    "history = train.fit_generator(gen, steps_per_epoch=n_batches, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infdec.save('models/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pred_embeddings(vocab, infenc):\n",
    "    embeddings = np.ndarray((len(vocab), embed_size))\n",
    "    i = 0\n",
    "    buffer = []\n",
    "    buffer_size = 10000\n",
    "    embed = []\n",
    "    for wi, word in enumerate(vocab):\n",
    "        word = int2word[word2int[word]]\n",
    "        buffer.append(word2vec(char2int, word, 13))\n",
    "        embed.append(sem_embed[word2int[word]])\n",
    "        if len(buffer) == buffer_size or len(vocab) - wi < buffer_size:\n",
    "            buffer_np = np.stack(buffer).reshape((-1, 13, 309, 1))\n",
    "            embed = np.stack(embed)\n",
    "            result = infenc.predict([buffer_np, embed])\n",
    "            embeddings[i:i+len(buffer)] = result\n",
    "            i += len(buffer)\n",
    "            buffer = []\n",
    "            embed = []\n",
    "            if i % (4 *buffer_size) == 0:\n",
    "                print(\"Predicting: {0:.2f}%\".format((i * 100.0 / len(vocab))))\n",
    "    print(\"finished\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = pred_embeddings(vocab, infenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 13.43%\n",
      "Predicting: 26.86%\n",
      "Predicting: 40.29%\n",
      "Predicting: 53.72%\n",
      "Predicting: 67.15%\n",
      "Predicting: 80.58%\n",
      "Predicting: 94.01%\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "def pred_embeddings_multi(vocab, encoder, char2tup):\n",
    "    embeddings = np.ndarray((len(vocab), embed_size))\n",
    "    i = 0\n",
    "    buffer = []\n",
    "    buffer_size = 10000\n",
    "    for wi, word in enumerate(vocab):\n",
    "        word = int2word[word2int[word]]\n",
    "        convec, vowvec = word2vec_seperated(char2tup, word, n_chars, n_consonant, n_vowel)\n",
    "        mat = np.concatenate([convec, vowvec], axis=1)\n",
    "        buffer.append(mat)\n",
    "        if len(buffer) == buffer_size or len(vocab) - wi < buffer_size:\n",
    "            buffer_np = np.stack(buffer).reshape((-1, n_chars, (n_consonant + n_vowel), 1))\n",
    "            result = encoder.predict(buffer_np)\n",
    "            embeddings[i:i+len(buffer)] = result\n",
    "            i += len(buffer)\n",
    "            buffer = []\n",
    "            if i % (4 *buffer_size) == 0:\n",
    "                print(\"Predicting: {0:.2f}%\".format((i * 100.0 / len(vocab))))\n",
    "    print(\"finished\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = pred_embeddings_multi(vocab, multi_enc, char2tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ፈላልጠህ ለያይንU\n",
      "ንድፍና ንንግፋ\n",
      "የማይስማማው የያልያጋUU\n",
      "ሳይነስ ሳይሰU\n",
      "የሚያገናኘን የያያየጋጣ\n",
      "ጃኮብ ድሽች\n",
      "ከማወጣ ከካ*ዛ\n",
      "በከፍተኛ በበችገኛ\n",
      "በብረት በብተይ\n",
      "አሳልፈው አላልቸU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in range(len(test_vocab)):\n",
    "#     word = test_vocab[i]\n",
    "#     result = decode_sequence(infdec, int2char, embeddings[word2int[word]].reshape((1, -1)))\n",
    "#     result = ''.join(result).strip()#[1:-1]\n",
    "#     print(word, result)\n",
    "#     if i ==  10:\n",
    "#         break\n",
    "rand_vocab = np.random.choice(vocab, 10)\n",
    "for i in range(10):\n",
    "    word = rand_vocab[i]\n",
    "    result = decode_multi_sequence(multi_dec, char2tup, tup2char, \n",
    "                                   embeddings[word2int[word]].reshape((1, -1)), n_consonant, n_vowel)\n",
    "    result = ''.join(result).strip()#[1:-1]\n",
    "    print(word, result)\n",
    "    if i ==  10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_normal = normalize(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly: 68.81% semantic: 1.08% syntactic: 11.36% \n"
     ]
    }
   ],
   "source": [
    "evaluate(embedding_normal, embed_size=embed_size, word2int=word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amany\\appdata\\local\\conda\\conda\\envs\\gputf3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly: 72.48% semantic: 0.00% syntactic: 6.82% \n"
     ]
    }
   ],
   "source": [
    "np.save(\"results/char_embedding\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenses = open('data/news.txt', encoding='utf-8').read().split('*')\n",
    "sentenses = [s.strip().split() for s in sentenses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'result/char_embedding.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-072605ae713f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"result/char_embedding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\amany\\appdata\\local\\conda\\conda\\envs\\gputf3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'result/char_embedding.npy'"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentenses, \n",
    "                            size=128, \n",
    "                            iter=20, \n",
    "                            min_count=1,\n",
    "                            negative=10,\n",
    "                            sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model.accuracy('data/syntax.txt')\n",
    "result2 = model.accuracy('data/semantic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_embed = np.ndarray((len(vocab), 128))\n",
    "for voc in vocab:\n",
    "    if voc is not '*':\n",
    "        sem_embed[word2int[voc]] = model.wv[voc]\n",
    "np.save(\"results/word2vec_embedding\", sem_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_embed_normal = normalize(sem_embed)\n",
    "# emb_norm = normalize(embeddings)\n",
    "# ee = sem_embed + embeddings*.1366\n",
    "# full_embed = np.concatenate([5*sem_embed_normal, 2*emb_norm], axis=1)\n",
    "full_embed_normal = sem_embed_normal + embedding_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_embed_normal = normalize(embedding_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(full_embed_normal, word2int, embed_size=full_embed_normal.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_model, emu_pred = embeder3(128, 128)\n",
    "adam = keras.optimizers.Nadam(0.0001)\n",
    "sgd = keras.optimizers.SGD(.01)\n",
    "emu_model.compile(optimizer=adam, loss='mse')\n",
    "batch_size = 500\n",
    "skip_window = 5\n",
    "gen4 = generate4(int_words, embeddings, word2int, batch_size, skip_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(words) // batch_size\n",
    "history = emu_model.fit_generator(gen4, steps_per_epoch=n_batches, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myembedding_norm=emu_model.predict(embedding_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myembeddings = normalize(myembedding_norm)\n",
    "# sem_embed_normal = normalize(sem_embed)\n",
    "ee = myembeddings #+ sem_embed_normal\n",
    "evaluate(ee, word2int, embed_size=myembeddings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min = 1\n",
    "# b = embedding_normal[0]\n",
    "# for i in range(len(embedding_normal)):\n",
    "#     a = embedding_normal[i]\n",
    "#     d = a.dot(b)\n",
    "#     if d < min:\n",
    "#         print(d)\n",
    "#         min = d\n",
    "# embedding_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_words(words, start, length):\n",
    "    if start + length > len(words):\n",
    "        end = start + length - len(words)\n",
    "        return words[start:] + words[0:end], end\n",
    "    else:\n",
    "        end = start + length\n",
    "        return words[start:end], end\n",
    "\n",
    "def get_context_words(words, start, length):\n",
    "    if start + length > len(words):\n",
    "        start = 0\n",
    "    end = start + length\n",
    "    return words[start:end], start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(data, embeds, word2int, int2word, unigrams, batch_size, skip_window):\n",
    "    embed_szie = embeds.shape[1]\n",
    "    assert batch_size % skip_window == 0\n",
    "    ci = skip_window  # current_index\n",
    "    batch_y = np.ones(shape=(batch_size, 1), dtype=np.float32)\n",
    "    while True:\n",
    "        batch_inputs = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_labels = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_index = 0\n",
    "        shuffle_index = np.random.shuffle(np.arange(batch_size))\n",
    "        for batch_index in range(0, batch_size, skip_window * 2):  # fill the batch inputs\n",
    "            context = data[ci - skip_window:ci + skip_window + 1]\n",
    "            # remove the target from context words\n",
    "            target = context.pop(skip_window)\n",
    "            # context = random.sample(context, skip_window * 2)\n",
    "            word_index = 0\n",
    "            for b in range(batch_index, batch_index + skip_window * 2):\n",
    "                con_vec = embeds[word2int[context[word_index]]]\n",
    "                target_vec = embeds[word2int[target]]\n",
    "                batch_inputs[b] = con_vec\n",
    "                batch_labels[b] = target_vec\n",
    "                word_index += 1\n",
    "\n",
    "            ci += 1\n",
    "        if len(data) - ci - skip_window < batch_size:\n",
    "            ci = skip_window\n",
    "        for ri  in range(0, batch_size, 2):\n",
    "            batch_labels[ri] = embeds[np.random.randint(len(embeds))]\n",
    "            batch_y[ri][0] = batch_labels[ri].dot(batch_inputs[ri])\n",
    "#         print(batch_labels.shape)\n",
    "#         batch_labels = batch_labels[shuffle_index].reshape((-1, 128))\n",
    "# #         print(batch_labels.shape)\n",
    "#         batch_inputs = batch_inputs[shuffle_index].reshape((-1, 128))\n",
    "#         batch_y = batch_y[shuffle_index].reshape((-1, 1))\n",
    "        yield [batch_inputs, batch_labels], batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate2(data, embeds, word2int, batch_size, skip_window):\n",
    "    embed_size = embeds.shape[1]\n",
    "    assert batch_size % skip_window == 0\n",
    "    ci = skip_window  # current_index\n",
    "    input_width = embed_size * 2 * skip_window\n",
    "    while True:\n",
    "        batch_inputs = np.ndarray(shape=(batch_size, input_width), dtype=np.float32)\n",
    "        batch_labels = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_index = 0\n",
    "        for batch_index in range(batch_size):  # fill the batch inputs\n",
    "            context = data[ci - skip_window:ci + skip_window + 1]\n",
    "            target = context.pop(skip_window)\n",
    "#             print(context, target)\n",
    "            context_vec = []\n",
    "            target_vec = embeds[word2int[target]]\n",
    "            for word in context:\n",
    "                con_vec = embeds[word2int[word]]\n",
    "                context_vec.append(con_vec)\n",
    "            context_vec = np.hstack(context_vec)\n",
    "#             batch_inputs[batch_index] = context_vec\n",
    "#             batch_labels[batch_index] = target_vec\n",
    "            \n",
    "            ci += 1\n",
    "        if len(data) - ci - skip_window < batch_size:\n",
    "            ci = skip_window\n",
    "        yield batch_inputs, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate3(data, embeds, word2int, batch_size, skip_window):\n",
    "    embed_size = embeds.shape[1]\n",
    "    ci = 0  # current_word_index\n",
    "    input_width = embed_size * 2 * skip_window\n",
    "    while True:\n",
    "        batch_inputs_left = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_inputs_right = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_labels = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_index = 0\n",
    "        for batch_index in range(batch_size):  # fill the batch inputs\n",
    "            context, ci = get_context_words(data, ci, 3)\n",
    "            ci = ci + 1\n",
    "            left_word_vec = embeds[word2int[context[0]]]\n",
    "            target_vec = embeds[word2int[context[1]]]\n",
    "            right_word_vec = embeds[word2int[context[2]]]\n",
    "            batch_inputs_left[batch_index] = left_word_vec\n",
    "            batch_inputs_right[batch_index] = right_word_vec\n",
    "            batch_labels[batch_index] = target_vec\n",
    "\n",
    "        yield [batch_inputs_left, batch_inputs_right], batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate4(data, embeds, word2int, batch_size, skip_window):\n",
    "    embed_size = embeds.shape[1]\n",
    "    ci = 0  # current_word_index\n",
    "    input_width = embed_size\n",
    "    while True:\n",
    "        batch_inputs = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        batch_labels = np.ndarray(shape=(batch_size, embed_size), dtype=np.float32)\n",
    "        for batch_index in range(0, batch_size, skip_window):  # fill the batch inputs\n",
    "            context, ci = get_context_words(data, ci, skip_window * 2 + 1)\n",
    "            ci = ci + 1\n",
    "            target = context.pop(skip_window)\n",
    "            context = np.random.choice(context, skip_window)\n",
    "            context_vec = embeds[context[0]]\n",
    "            target_vec = embeds[context[1]]\n",
    "            \n",
    "            batch_inputs[batch_index:batch_index +\n",
    "                             skip_window] = embeddings[context]\n",
    "            batch_labels[batch_index:batch_index +\n",
    "                             skip_window] = embeddings[target]\n",
    "\n",
    "        yield batch_inputs, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen3 = generate3(words, embedding_normal, word2int, batch_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3\n",
    "semantic_batch_size = 120\n",
    "input_size = 128\n",
    "# gg =  generate2(words, embeds_norm, word2int, batch_size=semantic_batch_size, skip_window=window) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model, con_model, tar_model = embedding_model3(input_size, 128, embed_size)\n",
    "adam = keras.optimizers.Nadam(0.0001)\n",
    "train_model.compile(optimizer=adam, loss=\"mse\")\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(words) // semantic_batch_size\n",
    "history = train_model.fit_generator(gen3, steps_per_epoch=n_batches, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generate(words, embedding_normal, word2int, int2word, ns_unigrams, batch_size=semantic_batch_size, skip_window=3)\n",
    "[a, b], y = next(g)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128#window * 2* embed_size\n",
    "# em_train, em_out = embedding_model(input_size, 128, embed_size)\n",
    "# adam = keras.optimizers.Nadam(lr=0.002)\n",
    "# em_train.compile(optimizer=adam, loss='mean_squared_error')\n",
    "# em_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model, con_model, tar_model = embedding_model2(input_size, 128, embed_size)\n",
    "adam = keras.optimizers.SGD(0.001)\n",
    "train_model.compile(optimizer=adam, loss=\"mse\", metrics=['mse', 'acc'])\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(words) // semantic_batch_size\n",
    "history = train_model.fit_generator(g, steps_per_epoch=n_batches, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vecs = []\n",
    "for i_word in range(len(vocab)):\n",
    "    word = int2word[i_word]\n",
    "    context_vecs.append(embedding_normal[word2int[word]])\n",
    "context_vecs = np.stack(context_vecs)\n",
    "context_embed = con_model.predict(context_vecs)\n",
    "# target_embed = tar_model.predict(context_vecs)\n",
    "# em = context_embed + target_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_normal = normalize(full_embed)\n",
    "evaluate(em_normal, word2int, embed_size=em_normal.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = Utils(word2int,int2word, embedding_normal)\n",
    "# v = -em_normal[word2int['ገንዘብ']] + em_normal[word2int['ብር']]\n",
    "# dots = em_normal.dot(v).flatten()\n",
    "# int2word[np.argmax(dots)]\n",
    "utils.sorted_sim(\"ዶላር\")\n",
    "# utils.sorted_sim(\"ብር\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_input = [\n",
    "    embedding_normal[word2int['ነበር']].reshape((1, 128)),\n",
    "    embedding_normal[word2int['ነው']].reshape((1, 128)),\n",
    "]\n",
    "vec = train_model.predict(con_input).flatten()\n",
    "print(embedding_normal[word2int['ነበር']].dot(embedding_normal[word2int['ነው']]))\n",
    "int2word[np.argmax(embedding_normal.dot(vec))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 1\n",
    "b = em_normal[0]\n",
    "for i in range(len(em_normal)):\n",
    "    a = em_normal[i]\n",
    "    d = a.dot(b)\n",
    "    if d < min:\n",
    "        print(d)\n",
    "        min = d\n",
    "# embedding_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# semantic = em_out.predict(embeds_norm)\n",
    "# gensim = GensimWrapper(embed_size, 0, log=True)\n",
    "# embeds = embeds.reshape((-1, 128))\n",
    "# norms = np.linalg.norm(semantic, axis=1, keepdims=True)\n",
    "# semantic_norm = semantic / norms\n",
    "vecs = []\n",
    "discovered = {}\n",
    "for i in range(window, len(words) - window):\n",
    "    context = words[i - window: i + window + 1]\n",
    "    target = context.pop(window)\n",
    "    if target not in discovered:\n",
    "        discovered[target] = len(discovered)\n",
    "        c_vec = []\n",
    "        for cword in context:\n",
    "            vec = embeds_norm[word2int[cword]]\n",
    "            c_vec.append(vec)\n",
    "        context_vec = np.hstack(c_vec)\n",
    "        vecs.append(context_vec)\n",
    "    if len(discovered) == len(vocab):\n",
    "        print(\"discovered\")\n",
    "        break\n",
    "    \n",
    "semantic = np.stack(vecs).reshape(-1, input_size)\n",
    "print(len(vecs), embeds_norm.shape)\n",
    "assert semantic.shape[0] == embeds_norm.shape[0]\n",
    "# semantic = em_out.predict(embeds_norm)\n",
    "# gensim = GensimWrapper(embed_size, 0, log=True)\n",
    "# embeds = embeds.reshape((-1, 128))\n",
    "# norms = np.linalg.norm(semantic, axis=1, keepdims=True)\n",
    "# semantic_norm = semantic / norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
